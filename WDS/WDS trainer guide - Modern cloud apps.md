![Microsoft Cloud Workshops](https://github.com/Microsoft/MCW-Template-Cloud-Workshop/raw/main/Media/ms-cloud-workshop.png 'Microsoft Cloud Workshops')

<div class="MCWHeader1">
Modern cloud apps
</div>

<div class="MCWHeader2">
 Whiteboard design session trainer guide
</div>

<div class="MCWHeader3">
December 2021
</div>

Information in this document, including URL and other Internet Web site references, is subject to change without notice. Unless otherwise noted, the example companies, organizations, products, domain names, e-mail addresses, logos, people, places, and events depicted herein are fictitious, and no association with any real company, organization, product, domain name, e-mail address, logo, person, place or event is intended or should be inferred. Complying with all applicable copyright laws is the responsibility of the user. Without limiting the rights under copyright, no part of this document may be reproduced, stored in or introduced into a retrieval system, or transmitted in any form or by any means (electronic, mechanical, photocopying, recording, or otherwise), or for any purpose, without the express written permission of Microsoft Corporation.

Microsoft may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter in this document. Except as expressly provided in any written license agreement from Microsoft, the furnishing of this document does not give you any license to these patents, trademarks, copyrights, or other intellectual property.

The names of manufacturers, products, or URLs are provided for informational purposes only and Microsoft makes no representations and warranties, either expressed, implied, or statutory, regarding these manufacturers or the use of the products with any Microsoft technologies. The inclusion of a manufacturer or product does not imply endorsement of Microsoft of the manufacturer or product. Links may be provided to third party sites. Such sites are not under the control of Microsoft and Microsoft is not responsible for the contents of any linked site or any link contained in a linked site, or any changes or updates to such sites. Microsoft is not responsible for webcasting or any other form of transmission received from any linked site. Microsoft is providing these links to you only as a convenience, and the inclusion of any link does not imply endorsement of Microsoft of the site or the products contained therein.

Â© 2020 Microsoft Corporation. All rights reserved.

Microsoft and the trademarks listed at https://www.microsoft.com/en-us/legal/intellectualproperty/Trademarks/Usage/General.aspx are trademarks of the Microsoft group of companies. All other trademarks are property of their respective owners.

**Contents**

<!-- TOC -->

- [Trainer information](#trainer-information)
  - [Role of the trainer](#role-of-the-trainer)
  - [Whiteboard design session flow](#whiteboard-design-session-flow)
  - [Before the whiteboard design session: How to prepare](#before-the-whiteboard-design-session-how-to-prepare)
  - [During the whiteboard design session: Tips for an effective whiteboard design session](#during-the-whiteboard-design-session-tips-for-an-effective-whiteboard-design-session)
- [Modern cloud apps whiteboard design session student guide](#modern-cloud-apps-whiteboard-design-session-student-guide)
  - [Abstract and learning objectives](#abstract-and-learning-objectives)
  - [Step 1: Review the customer case study](#step-1-review-the-customer-case-study)
    - [Customer situation](#customer-situation)
    - [Customer needs](#customer-needs)
    - [Customer objections](#customer-objections)
    - [Infographic for common scenarios](#infographic-for-common-scenarios)
  - [Step 2: Design a proof of concept solution](#step-2-design-a-proof-of-concept-solution)
  - [Step 3: Present the solution](#step-3-present-the-solution)
  - [Wrap-up](#wrap-up)
  - [Additional references](#additional-references)
- [Modern cloud apps whiteboard design session trainer guide](#modern-cloud-apps-whiteboard-design-session-trainer-guide)
  - [Step 1: Review the customer case study](#step-1-review-the-customer-case-study-1)
  - [Step 2: Design a proof of concept solution](#step-2-design-a-proof-of-concept-solution-1)
  - [Step 3: Present the solution](#step-3-present-the-solution-1)
  - [Wrap-up](#wrap-up-1)
  - [Preferred target audience](#preferred-target-audience)
  - [Preferred solution](#preferred-solution)
  - [Checklist of preferred objection handling](#checklist-of-preferred-objection-handling)
  - [Customer quote (to be read back to the attendees at the end)](#customer-quote-to-be-read-back-to-the-attendees-at-the-end)

<!-- /TOC -->

# Trainer information

Thank you for taking time to support the whiteboard design sessions as a trainer!

## Role of the trainer

An amazing trainer:

- Creates a safe environment in which learning can take place.

- Stimulates the participant's thinking.

- Involves the participant in the learning process.

- Manages the learning process (on time, on topic, and adjusting to benefit participants).

- Ensures individual participant accountability.

- Ties it all together for the participant.

- Provides insight and experience to the learning process.

- Effectively leads the whiteboard design session discussion.

- Monitors quality and appropriateness of participant deliverables.

- Effectively leads the feedback process.

## Whiteboard design session flow

Each whiteboard design session uses the following flow:

**Step 1: Review the customer case study (15 minutes)**

**Outcome**

Analyze your customer's needs.

- Customer's background, situation, needs and technical requirements

- Current customer infrastructure and architecture

- Potential issues, objectives and blockers

**Step 2: Design a proof of concept solution (60 minutes)**

**Outcome**

Design a solution and prepare to present the solution to the target customer audience in a 15-minute chalk-talk format.

- Determine your target customer audience.

- Determine customer's business needs to address your solution.

- Design and diagram your solution.

- Prepare to present your solution.

**Step 3: Present the solution (30 minutes)**

**Outcome**

Present solution to your customer:

- Present solution

- Respond to customer objections

- Receive feedback

**Wrap-up (15 minutes)**

- Review preferred solution

## Before the whiteboard design session: How to prepare

Before conducting your first whiteboard design session:

- Read the Student guide (including the case study) and Trainer guide.

- Become familiar with all key points and activities.

- Plan the point you want to stress, which questions you want to drive, transitions, and be ready to answer questions.

- Prior to the whiteboard design session, discuss the case study to pick up more ideas.

- Make notes for later.

## During the whiteboard design session: Tips for an effective whiteboard design session

**Refer to the Trainer guide** to stay on track and observe the timings.

**Do not expect to memorize every detail** of the whiteboard design session.

When participants are doing activities, you can **look ahead to refresh your memory**.

- **Adjust activity and whiteboard design session pace** as needed to allow time for presenting, feedback, and sharing.

- **Add examples, points, and stories** from your own experience. Think about stories you can share that help you make your points clearly and effectively.

- **Consider creating a "parking lot"** to record issues or questions raised that are outside the scope of the whiteboard design session or can be answered later. Decide how you will address these issues, so you can acknowledge them without being derailed by them.

***Have fun**! Encourage participants to have fun and share!*

**Involve your participants.** Talk and share your knowledge but always involve your participants, even while you are the one speaking.

**Ask questions** and get them to share to fully involve your group in the learning process.

**Ask first**, whenever possible. Before launching into a topic, learn your audience's opinions about it and experiences with it. Asking first enables you to assess their level of knowledge and experience, and leaves them more open to what you are presenting.

**Wait for responses**. If you ask a question such as, "What's your experience with (fill in the blank)?" then wait. Do not be afraid of a little silence. If you leap into the silence, your participants will feel you are not serious about involving them and will become passive. Give participants a chance to think, and if no one answers, patiently ask again. You will usually get a response.

# Modern cloud apps whiteboard design session student guide

## Abstract and learning objectives

In this whiteboard design session, you will work with a group to design a solution to modernize CSLA's e-commerce and back-end services, while maintaining existing PCI compliance. To ensure compliance, you will ensure data privacy and protection across all aspects of the system, in transit and at rest. The goal is to use Azure PaaS services for the public-facing and back-end websites, while providing a way for the on-premises components to securely communicate with these services. You will also design fault-tolerance and a regional failover plan of the Azure components.

By the end of this whiteboard design session, you will have a better understanding of how to modernize a legacy web app by retargeting it for the cloud, taking advantage of the many services Azure provides to enhance functionality and secure your solution's components by following best practices for PCI compliance and security.

## Step 1: Review the customer case study 

**Outcome**

Analyze your customer's needs.

Timeframe: 15 minutes

Directions: With all participants in the session, the facilitator/SME presents an overview of the customer case study along with technical tips.

1. Meet your team members and trainer.

2. Read all directions for steps 1-3 in the student guide.

3. As a team, review the following customer case study.

### Customer situation

The Contoso Sports League Association (CSLA) is one of the largest sports franchises. They have over 100 championships in their history and a huge, passionate fan base. They run a highly successful e-commerce website that sells merchandise to their legions of sports fans. The website is built using ASP.NET Core and currently hosted in a co-location.

They accept payment by credit card and owing to their high annual volume (in the tens of millions, processing about 50K per day) of transactions, need to ensure that they are Payment Card Industry Data Security Standards (PCI DSS) Level 1 compliant. Their website hosts the shopping cart and checkout process, but they defer the credit card authorization and capture responsibilities of the credit card processing to a third-party payment gateway. This payment gateway provides a web application programming interface (API) that is invoked over Transport Layer Security (TLS) from Contoso server-side logic. The call includes the credit card holder data (name, number, and so on) and returns a status indicating a success or failure in authorizing and capturing payment against the credit card. It is called after the customer clicks checkout, as a part of processing the order. They currently store their customer and profile data in SQL Server 2014.

In addition to the public facing e-commerce website, they have a backend website that supports their call center. Call center employees use this admin website to view customer orders. Customers can call in to the call center to place orders and pay for orders with their credit cards by phone.

CSLA manages the order fulfillment process. When an order arrives, they store the order details in their SQL database, and send a message for each order to their inventory management system running the warehouse. CSLA experiences a roughly 12-hour window that spans east to west coast business hours, during which they get most of their orders. The warehouse receives the message (which simply contains the order ID from the database), pulls up the order details identified in the message (by a lookup against the database), and then for each item in the order queues up a separate process to locate the item in inventory or place an order for it with their supplier. Once this initial status for each item in the order is collected, the inventory status is updated in the database and a confirmation email is sent to the customer indicating the estimated delivery date of their completed order (and if any items are in backorder). This inventory lookup rarely takes more than a few hours and never more than a day.

They have reached a point where managing their server infrastructure is becoming a real challenge. Contoso wants to understand more about platform as a service (PaaS) solutions. They wonder if PaaS could help them focus their efforts more on the core business value rather than infrastructure. They have observed that Azure has received PCI compliance certification and are interested in moving their solution to Azure. "We're finding that with every upgrade, we're spending more and more engineering time on infrastructure and less on the experience that matters most to our fan base," says Miles Strom, Chief Executive Officer (CEO) of Contoso Sports League Association, "we need to rebalance those efforts."

One example is in how they manage the usernames and passwords for call center operators and support staff, as applied to the call center admin website. Today they have a homegrown solution that stores usernames and passwords in the same database used for storing merchandise information. They have experimented with other third-party solutions in the past, and their employees found it jarring to see another company's logo displayed when logging into their own call center website. In creating their identity solution, they want to ensure they can brand the login screens with their own logo. Additionally, Contoso is concerned about hackers from foreign countries/regions gaining access to the administrator site. Before they choose an identity solution, they would like to see how it indicates such attempts.

Contoso is interested in achieving automation surrounding their currently manual release processes. They wish to have features developed in their own branch. Once the feature is complete, a pull request is issued to the master branch. The pull request code is then reviewed for quality assurance, and once approved, the code is merged into the master branch. The merge of the code should trigger an automated deployment to release the new application code into production.

There is one architectural enhancement Contoso would like to make in the transition to a PaaS solution. When a visitor loads the home page, it gets the list of featured products on offer (consisting of the product image, title, and URL) from the Offers service. The home page does it using a client-side GET request against an ASP.NET Web API service that is executed as the page loads in the browser. Contoso anticipates growing the functionality of this service and would like to scale it independently of the website.

Contoso is also looking to augment their data analytics story by introducing a data warehouse to enable them to analyze their historical data over time, particularly as their number of transactions soars in the cloud. They would like to plan for a solution that moves the data from their OLTP database into their data warehouse on a nightly basis, ideally with the minimum amount of infrastructure or development effort.

### Customer needs

1. Make architectural decisions that help to minimize engineering around infrastructure in favor of those that deliver core business value. Contoso is interested in understanding more about PaaS solutions.

2. Maintain existing PCI compliance.

3. Ensure data privacy and protection across all aspects of the system, in transit and at rest.

4. They want to be able to scale their offers' API independently of the website.

5. Ensure that they retain their core functionality, even if the way it is accomplished under the covers might change.

6. Provide a better solution for the management of usernames and passwords.

7. Provide a regional database failover plan that will enable the customer to initiate the failover to another region, allowing their various web applications and other hosted services to roll over to a synchronized database at minimal cost.

8. A data warehouse for analyzing their transaction history.

### Customer objections

1. It is not clear to us from the Azure Trust Center just how Azure helps our solution become PCI compliant.

2. Can we provide a solution that scales to meet our public demand, but is also secure for use by our call center and warehouse?

3. Our PCI compliance requires us to have a quarterly audit and to conduct occasional penetration tests. Is it supported by Azure?

4. Can we audit the Azure data center?

5. In the past, we have relied on SOASTA CloudTest to design and execute our web load tests at scale. In moving to Azure, are we still take advantage of CloudTest?

6. Our previous infrastructure did not have great performance monitoring of our websites. What options would you recommend we investigate that would work with our web apps in Azure?

7. We have heard that Azure's data warehouse can be paused. Does that mean we must store all our data in Azure Storage first before we can pause the instances and risk losing our data?

8. We know it's possible to use Azure SQL Database as our data warehouse. What should we consider when deciding between this and Azure Synapse Analytics?

### Infographic for common scenarios

![This diagram is of a Common scenario for an E-Commerce Website. The diagram begins with an end user, includes a services tier, internet tier, and data tier, and ends at an Enterprise. The diagram also includes Microsoft Azure, and Azure Virtual Network.](media/image2.png 'Common scenario for an E-Commerce Website')

## Step 2: Design a proof of concept solution

**Outcome**

Design a solution and prepare to present the solution to the target customer audience in a 15-minute chalk-talk format.

Timeframe: 60 minutes

**Business needs**

Directions: With your team, answer the following questions and be prepared to present your solution to others:

1. Who will you present this solution to? Who is your target customer audience? Who are the decision makers?

2. What customer business needs do you need to address with your solution?

**Design**

Directions: With your team, respond to the following questions:

*High-level architecture*

1. Without getting into the details, the following sections will address the details, diagram your initial vision for handling the top-level requirements for the e-commerce website, call center website, and inventory lookup process. You will refine this diagram as you proceed.

*Order fulfillment*

1. How would you recommend CSLA manage the inventory lookup queues? How would you help CSLA decide between Azure Queues and Service Bus? Be sure to consider details implied by CSLA's requirements such as volume, message lifetime, and sizing. Explain the details of any computations you make.

*Notifications*

1. How would you recommend CSLA manage notifying customers as their order in the CSLA orders database is processed? Are there specific Azure services that can be used? Include details on how this would be implemented and integrated into the proposed solution for CSLA.

*Offers service*

1. Would you propose Contoso use the Azure App Service API app to meet their requirements for the Offers service?

2. If so, what specific configurations would you need to make to support your proposed topology? Specifically, how would you implement the changes and configurations required to allow for inter-app communication between the e-commerce application and the Offers service?

*Geo-resiliency*

1. How would you implement high availability for the orders database to guard against regional data center outages? Be specific on how you would configure SQL Database and Azure Storage.

2. What process would you recommend to the customer to failover in the event of an outage, ensuring their web applications and associated Azure services change over to a secondary region?

3. How long would a failover take and how much data could be lost, in terms of time?

*Access control*

1. With respect to managing access to the call center website, explain how you would recommend Contoso implement a solution that meets their requirements. Be specific about both the implementation and the process you would use to gain Contoso's acceptance of the proposed solution.

*Enabling PCI compliance*

1. Keeping only the e-commerce website and handling of cardholder data in scope for PCI, consider the following in your design:

    - Are web apps deployed in Azure App Service Environments an option?

    - Explain how using Azure App Service Environments could address the PCI requirements.

    - Keeping in mind the best choice for securing inbound and outbound traffic for an App Service Environment, detail all inbound and outbound traffic for this solution that allows it to be PCI compliant and allows it to operate within Azure. It should include traffic into and out of the solution, outbound for the e-commerce website, and any other traffic between the apps within the solution.

    - Make sure to describe in detail the network topology you are using.

    - For any inbound and outbound application communications you are securing, please detail the specific mechanisms you will use to do so.

    - If your approach includes configuration scripts, please provide an example of the scripts.

2. Would you recommend they use Azure virtual machines? Why or why not?

*Data warehouse*

1. How would you recommend Contoso implement their data warehouse?

2. How would Contoso schedule nightly data transfers from their OLTP database to their data warehouse?

*Automated deployment*

1. How would you recommend Contoso implement their automated deployments?

2. How would Contoso implement the trigger for the automated deployment?

**Prepare**

Directions: As a team:

1. Identify any customer needs that are not addressed with the proposed solution.

2. Identify the benefits of your solution.

3. Determine how you will respond to the customer's objections.

Prepare a 15-minute chalk-talk style presentation to the customer.

## Step 3: Present the solution

**Outcome**

Present a solution to the target customer audience in a 15-minute chalk-talk format.

Timeframe: 30 minutes

**Presentation**

Directions:

1. Pair with another team.

2. One group is the Microsoft team and the other is the customer.

3. The Microsoft team presents their proposed solution to the customer.

4. The customer makes one of the objections from the list of objections.

5. The Microsoft team responds to the objection.

6. The customer team gives feedback to the Microsoft team.

7. Switch roles and repeat Steps 2-6.

##  Wrap-up 

Timeframe: 15 minutes

Directions: Reconvene with the larger group to hear the facilitator/SME share the preferred solution for the case study.

## Additional references

| Description                                                  | Links        |
| :------------------------------------------------------------ | :----------- |
| Compliance Commitments                                       |                              <http://azure.microsoft.com/en-us/support/trust-center/services/>                              |
| Azure App Services                                           |                 <https://azure.microsoft.com/en-us/documentation/articles/app-service-value-prop-what-is/>                  |
| Azure Service Environment (ASE)                              |            <https://azure.microsoft.com/en-us/documentation/articles/app-service-app-service-environment-intro/>            |
| Integrate ILB ASE with Azure Application Gateway             |             <https://docs.microsoft.com/en-us/azure/app-service/environment/integrate-with-application-gateway>             |
| Configuring ASE Network Security Groups                      |            <https://docs.microsoft.com/en-us/azure/app-service/environment/network-info#network-security-groups>            |
| Geo Distributed Scale with ASE                               | <https://docs.microsoft.com/en-us/azure/app-service/environment/app-service-app-service-environment-geo-distributed-scale>  |
| Azure Trust Center                                           |                                  <http://azure.microsoft.com/en-us/support/trust-center/>                                   |
| Azure PCI Attestation of Compliance                          |   <http://download.microsoft.com/download/7/1/E/71E02A19-D1A4-448F-8CEA-D6A19398ABDA/Azure%20PCI%20AOC%20Feb%202015.pdf>    |
| PCI DSS v3.0                                                 |                               <https://www.pcisecuritystandards.org/documents/PCI_DSS_v3.pdf>                               |
| Azure Data Factory                                           | <https://azure.microsoft.com/en-us/documentation/articles/data-factory-data-movement-activities/#data-factory-copy-wizard/> |
| Azure SQL Database                                           |                <https://docs.microsoft.com/en-us/azure/sql-database/sql-database-geo-replication-overview/>                 |
| Designing highly available services using Azure SQL Database |     <https://docs.microsoft.com/en-us/azure/sql-database/sql-database-designing-cloud-solutions-for-disaster-recovery>      |
| SQL Database auto-failover groups | <https://docs.microsoft.com/en-us/azure/sql-database/sql-database-auto-failover-group?tabs=azure-powershell> |
| Deploy to Azure using GitHub Actions | <https://docs.microsoft.com/en-us/azure/developer/github/github-actions> |


# Modern cloud apps whiteboard design session trainer guide

## Step 1: Review the customer case study

- Check in with your participants to introduce yourself as the trainer.

- Ask, "What questions do you have about the customer case study?"

- Briefly review the steps and timeframes of the whiteboard design session.

- Ready, set, go! Let participants begin.

## Step 2: Design a proof of concept solution

- Check in with your teams to ensure that they are transitioning from step to step on time.

- Provide feedback on their responses to the business needs and design.

  - Try asking questions first that will lead the participants to discover the answers on their own.

- Provide feedback for their responses to the customer's objections.

  - Try asking questions first that will lead the participants to discover the answers on their own.

## Step 3: Present the solution

- Determine which groups will be paired together before Step 3 begins.

- For the first round, assign one group as the presenting team and the other as the customer.

- Have the presenting team present their solution to the customer team.

  - Have the customer team provide one objection for the presenting team to respond to.

  - The presentation, objections, and feedback should take no longer than 15 minutes.

  - If needed, the trainer may also provide feedback.

## Wrap-up

- Have participants reconvene with the larger session group to hear the facilitator/SME share the following preferred solution.

## Preferred target audience

Miles Strom, CEO of Contoso Sports League Association

The primary audience are the business decision makers and technology decision makers. Usually we talk to the infrastructure managers who report to the chief information offer (CIO), or to application sponsors (like a vice president \[VP\] line of business \[LOB\], or chief marketing officer \[CMO\]), or to those that represent the business unit IT or developers that report to application sponsors.

## Preferred solution

*High-level architecture*

1. Without getting into the details, (the following sections will address the details), diagram your initial vision for handling the top-level requirements for the e-commerce website, call center website, and inventory lookup process. You will refine this diagram as you proceed.

    The Contoso Sports League Association (CSLA) was motivated to move its solution to Azure. After analyzing their requirements across the e-commerce, inventory, and customer support apps, they built their solution from the following high-level designs.

    They decided on a solution that at a high level appears as follows:

    ![Diagram of the preferred solution. From a high-level, web apps hosting the e-commerce and call center websites access APIs hosted in API Apps, all hosted within an App Service Environment to enable secure communication. Access to call center website available through VPN connection only.](media/preferred-solution.png 'Preferred solution diagram')

    From a high-level, they have Web Apps hosting the e-commerce and call center websites, API Apps hosting web services and Logic Apps hosting integration with SMS. Azure Traffic Manager is used for routing to the appropriate region for high availability. The Web and API Apps can be hosted within an Internal Load Balanced (ILB) App Service Environment (ASE) that enables them to take advantage of Network Security Groups to lock down inbound and outbound communication to the App Services it hosts. A Web Application Firewall (WAF) provided by an Azure App Gateway is hosted in its own subnet and NSGs. Internet traffic flows through the WAF to the e-commerce website (hosted within the ASE), which only allows inbound traffic from the WAF. When customers visit the website, they are presented orders whose data comes from the Offers Service REST API hosted within an API App. Orders come in from customers via the publicly accessible endpoint of the e-commerce website. The credit card is validated as a part of the checkout process by making a call to a third-party payment gateway. Once authorized and payment is captured, the order data is stored in the orders database on SQL DB and the inventory lookup message is sent to the Inventory Lookup queue. An Azure Function hosts the process for creating the PDF receipts for customer purchases. Customers are notified via SMS as their order is processed. This process involves a process running in a Logic App that integrates the SQL DB with a third-party solution for sending SMS text messages.

    Inventory lookup requests are queued from the e-commerce website to the queue in Azure Storage queues. The on-premises inventory app reads from this queue to kick off its internal lookup processes and writes the status back to the orders database.

    Call center operators access the call center website which, owing to the NSGs configured, is only available across the virtual private network (VPN) connection.

>**Note**: The preferred solution is only one of many possible, viable approaches.

*Order fulfillment*

1. How would you recommend CSLA manage the inventory lookup queues? How would you help CSLA decide between Azure Queues and Service Bus? Be sure to consider details implied by CSLA's requirements such a volume, message lifetime, and sizing. Explain the details of any computations you make.

    Given that CSLA did not provide specific requirements that imply a need for the more advanced queuing features that Service Bus offers (such as topics, larger message sizes, longer message lifetime, and so on), CSLA should consider using Azure Queues because it meets their requirements and is the most cost effective.

    Their volume is low, at 50K transactions per day, it translates to 50K messages per day. Their actual load per unit of time depends on their actual peak order times that is implied to be akin to 9 a.m.to 9 p.m. EST. Assuming a consistent load during business hours, that equates to about 4,000 messages per hour, which is well below what Azure Queues can support (2,000 messages per second or approximately 120,000 messages per hour for messages sized below 1 kilobyte \[KB\]).

    The case study states that rarely does an inventory lookup message take longer than a few hours and never more than a day. It means that they will never encounter the 7-day lifetime limit required by messages in Azure Queues.

    As for the individual message size, since it is just the order ID from the database, it is unlikely to be a field larger than 64 KB (the maximum message size supported by Azure Queues), or even 1 KB (the size at which Azure Queues can handle 2,000 messages per second).

*Notifications*

1. How would you recommend CSLA manage notifying customers as their order in the CSLA orders database is processed? Are there specific Azure services that can be used? Include details on how this would be implemented and integrated into the proposed solution for CSLA?

    Contoso can implement a logic app to notify customers of their order status.

    The logic app would include a frequency trigger to execute a stored procedure at an interval that will identify orders that should receive SMS notifications and update them as they are processed.

    A Twilio connector could act as the action to perform that sends the SMS message when the frequency trigger executes the stored procedure. CSLA would sign up for a free Twilio trial to get an API key. Then they would provision a Twilio connector within the logic app, and add the credentials. Then CSLA would select a Send Message action using data provided in the result set from the stored procedure, specifically the customer's phone number and their first name to include in the message, "Hello Satya, your order has shipped!"

    >**Note**: It currently involves extending the Logic App code for the Twilio connector.

*Offers service*

1. Would you propose Contoso use the Azure App Service API app to meet their requirements for the Offers service?

    Contoso could meet their requirement of scaling the Offers API independently from the main website by separating it out from the website project into its own Web API project and deploying that project to an Azure App Service API App.

2. If so, what specific configurations would you need to make to support your proposed topology? Specifically, how would you implement the changes and configurations required to allow for inter-app communication between the e-commerce application and the Offers service?

    For the home page to be able to successfully retrieve the data from the now separate Web API (for example, it is located in another origin), cross origin resource sharing (CORS) would need to be configured.

    The API app would need to be enabled for CORS, and the domains used to access the website in the list of allowed origins would need to be listed.

    Second, the Web API code would need to be updated to include the System.Web.Http.Cors package, where CORS would need to be enabled in the WebApiConfig.cs file, and the EnableCors attribute would need to be applied to the controllers or actions of the Offers service allowing the aforementioned origins and allow the GET method.

    If Contoso chooses to open access of the Offers service for integration by partners they should also consider implementing API management in front of their API App hosted Web API. This would enable them to lock down access by requiring a key, apply policy (such as rate limiting requests), and monitor usage by API customers.

*Geo-resiliency*

1. How would you implement high availability for the orders database to guard against regional data center outages? Be specific on how you would configure SQL Database and Azure Storage_

    Azure SQL Database auto-failover groups is a SQL Database feature designed to automatically manage geo-replication relationship, connectivity, and failover at scale. With it, the customers gain the ability to automatically recover multiple related databases in the secondary region after catastrophic regional failures or other unplanned events that result in full or partial loss of the SQL Database service's availability in the primary region. Additionally, they can use the readable secondary databases to offload read-only workloads. Because auto-failover groups involve multiple databases, they must be configured on the primary server. Both primary and secondary servers must be in the same subscription. Auto-failover groups support replication of all databases in the group to only one secondary server in a different region. Active geo-replication, without auto-failover groups, allows up to four secondaries in any region.

    Provision the Azure Storage Account with RA-GRS redundancy with a primary and secondary geographic location matching those of the SQL databases, so that in the event of an outage all backup regions have copies of the data. It may affect your choice of SQL database secondary regions because the primary/secondary regions pairs for storage are predefined and not user selectable (e.g., West US primary will use East US as secondary). The replication between the primary storage account region and secondary storage account region is asynchronous to it does not impact the latency of requests made against the primary region, albeit some data loss might be possible if it has not replicated to the secondary region in the event of a disaster.

    Finally, deploy copies of the App Services to the backup regions. You will have to consider a process of how you update these instances when the primary region gets updates. These can initially be deployed to resources with minimal scale out instance sizes, and increased when failover event occurs.

2. What process would you recommend to the customer to failover in the event of an outage, ensuring their web applications and associated Azure services change over to a secondary region?

    When using auto-failover groups (in-preview) to manage database recovery and any outage that impacts one or several of the databases in the group results in automatic failover. You can configure the auto-failover policy that best meets your application needs, or you can opt out and use manual activation. Whether you use manual or automatic failover activation, failover switches all secondary databases in the group to primary. After the database failover is completed, the DNS record is automatically updated to redirect the end-points to the new region.

    Azure Traffic Manager can be used along with health probes to monitor the App Services hosted within each region. Traffic Manager routes all internet traffic to the Application Gateway WAF, which in turn securely connects into the ILB App Service Environment to the e-commerce website. If the health probes indicate a certain number of failures within a region, it automatically starts routing traffic to the secondary region. This topology can also be used for horizontally scaling out apps located within the geo-distributed ASEs, enabling extreme load handling. For geographic redundancy, the application's resources are deployed to Region 1 and 2.

    ![All internet traffic is routed through Traffic Manager, which will send traffic to a secondary region if the primary region is out](media/traffic-manager-region-failover.png 'Regional failover of app services with Traffic Manager')

    Understand that for Azure Storage, the geo-failover process is controlled by Azure. in the event of a major disaster that affects the primary location, Azure will first try to restore the data in the primary location. Failing that, affected customers will be notified via their subscription contact information. As part of the failover, the customer's "account.\<service\>.core.windows.net" DNS entry would be updated to point from the primary location to the secondary location. In other words, the connection information to Azure Storage does not need to be changed in the application configuration.

3. How long would a failover take and how much data could be lost, in terms of time?

    The amount of time a failover takes is the Recovery Time Objective (RTO) and the amount of data loss that might transpire due to any replication latency is the Recovery Point Objective (RPO).

    For SQL Database on the Premium Tier, the RTO is less than 30 seconds and the RPO is less than 5 seconds.

    For Azure Storage, the RTO is about 24 hours and the RPO is typically less than 15 minutes, although this has no explicit SLA. Given the potentially long RTO and RPO for Azure Storage, Contoso might consider using RA-GRS storage and when a failover happens use the RA-GRS for read and a separate storage account for the writing of new files.

*Access control*

1. With respect to managing access to the call center website, explain how you would recommend Contoso implement a solution that meets their requirements. Be specific about both the implementation and the process you would use to gain Contoso's acceptance of the proposed solution_

    Contoso could capitalize on Azure Active Directory to manage the user accounts for the call center staff. They would need to provision an Azure Active Directory tenant in the Premium Tier to provide the branding. Once they have the tenant, they can create login screen branding by using the management portal.

    ![Use the Azure Active Directory Status section to configure custom branding for your company.](media/image4.png 'Status section')

    From there they specify images for the banner logo, a tile logo, and large illustration, and provide some custom text.

    ![In the Configure company branding blade, select a file to use as the large image that displays to the left of the custom login form.](media/image5.png 'Configure company branding blade')

    It would result in something like the following for Contoso:

    ![Screenshot of the Contoso sign-in webpage.](media/image6.png 'Contoso sign-in webpage')

    With respect to addressing Contoso's concerns over foreign hackers, Azure Active Directory can help by identifying logins from multiple geographic locations by using the report "Sign ins from multiple geographies." To demonstrate the function of it to Contoso, one approach to accomplish a login from a foreign IP is to spin up a virtual machine in Azure in a foreign geography, remote desktop into it, open the browser, and navigate to the Contoso admin site and log in. Then log in from a local machine at the same time. Within an hour or two the suspicious login would be listed in the report.

    Provided that the call center administrator website is deployed to a web app and that currently anyone listed as a user in Azure Active Directory is a user who should have access to the call center website, since the case study does not stipulate any other more granular requirements, the setup for integrating Azure Active Directory access control requires no code on the part of Contoso, just configuration. This configuration is accomplished using the Azure portal (at https://portal.azure.com), navigating to the web app, and on the Settings blade selecting Authentication/Authorization. Then in the Authentication/Authorization blade, choose Login with Azure Active Directory, and then configure the Azure Active Directory authentication provider to create a new application in AAD or to use an existing application.

    ![On the Azure Portal, Authentication/Authorization blade, App Service Authorization is set to On, Users must Log in with Azure Active Directory when their request is not authenticated, and Authentication Provider is Azure Active Directory.](media/image7.png 'Azure Portal, Authentication/Authorization blade')

    Once applied, any access to the call center admin website will automatically be redirected to first log in through Azure Active Directory, and users would need to be created in Azure Active Directory to acquire access.

*Enabling PCI compliance*

1. Keeping only the e-commerce website and handling of cardholder data in scope for PCI, consider the following in your design:

    - Are web apps deployed in Azure App Service Environments an option?

    - Explain how using Azure App Service Environments could address the PCI requirements.

    - Keeping in mind the best choice for securing inbound and outbound traffic for an App Service Environment, detail all inbound and outbound traffic for this solution that allows it to be PCI compliant and allows it to operate within Azure. It should include traffic into and out of the solution, outbound for the e-commerce website, and any other traffic between the apps within the solution.

    - Make sure to describe in detail the network topology you are using.

    - For any inbound and outbound application communications you are securing, please detail the specific mechanisms you will use to do so.

    - If your approach includes configuration scripts, please provide an example of the scripts.

    While web apps are certified as PCI compliant, they are not immediately PCI compliant when used by the customer. The PCI requirements 1.2.1, 1.3.3, and 1.3.5 require restricting outbound access to only that which is necessary for the cardholder environment. In the case of CSLA, it means that the only outbound communication allowed should be to Azure (for monitoring) and to the payment gateway. Web apps in the Standard Tier have no mechanism for restricting the outbound traffic.

    To remedy this, the web and API App Services should be hosted within an App Service Environment (ASE), using Isolated Tiers. ASE v2 is an App Service feature that provides a fully isolated and dedicated environment for securely running App Service apps at high scale. The ASE itself provides a hosting infrastructure that is deployed within a subnet of a Virtual Network (VNET). The ASE exposes only an Internal Load Balancer (ILB) endpoint for access to the App Service instances it hosts. Then, an Application Gateway of the Web Application Firewall (WAF) SKU should be deployed between the public IP address used by Internet clients to access the website and the ILB ASE endpoint. The ASE and the Application Gateway are deployed to two different subnets. Network Security Groups (NSG) are configured so that the subnet that contains the ASE only allows access from the subnet which contains the Application Gateway.

    If restricting the _inbound_ communication (for example limiting by IP, port, protocol) to a web app from the Internet, then you need to:

    - Provision an ILB ASE, which will create an Azure Virtual Network.

    - Provision the app hosting plan from the ASE pool of resources, in an Isolated Tier.

    - Provision a web app in that App Service plan (no need to create a point-to-site VPN connection for the web app).

    - Provide an internet routable domain name to be used with the app in the ILB App Service Environment.

    - Provide a public DNS name that is used later to point to the Application Gateway.

    - Create a separate subnet from the one the ILB App Service Environment uses. This new subnet will be used for the Azure Application Gateway.

    - Create an Application Gateway inside the separate subnet, and configure it to point to the public web app within the ILB ASE. You must select the WAF tier during creation.

    - Configure the web app to honor the custom domain name and edit the public DNS host name that points to the Application Gateway.

    - Create an NSG and apply it to the virtual network subnet in which the ASE runs (by default the rules included will prevent access from the Internet).

    - The NSG contains a default rule that enables the IPs in the VNet to talk to the ASE subnet. Another default rule enables the load balancer, also known as the public VIP, to communicate with the ASE.

    - Add a rule to the NSG allowing Internet access to the ports 454-455. To see the ports, select App Service Environment > IP addresses.

    If you are interested in restricting the _outbound_ communication from a web app to a service on the Internet, then you need to:

    - Configure the ASE, virtual network, Azure Application Gateway, App Service plan, and web app as above.

    - Add two outbound rules to the NSG: one that allows access to permitted service and another that denies all outbound Internet.

    - Configure your outbound security rules to enable network access to the ASE dependencies. If you block any of them, your ASE stops working. Reference: <https://docs.microsoft.com/en-us/azure/app-service/environment/network-info#network-security-groups>

    For CSLA's situation, inbound access to the e-commerce web app does not need to be restricted, but the outbound communication to the payment gateway does need to be restricted.

    To meet the antivirus requirement, you need only deploy to Azure since that requirement is itself met by Azure and managed against the virtual machines running your web app on your behalf.

    By structuring the web app so all it does it handle the e-commerce transaction, you would meet the server specialization requirement. By capitalizing on web apps, you are inherently addressing the patching requirement since Azure handles that for you (except any custom code or libraries your application may use).

    There is no need to store cardholder data in this scenario, so by having SSL the requirement for protection of data in transit and at rest is also met.

2. Would you recommend they use Azure virtual machines? Why or why not?

    While virtual machines could certainly be used to enable a PCI compliant solution, they would not meet the customer requirement for minimizing infrastructure efforts.

*Data warehouse*

1. How would you recommend Contoso implement their data warehouse?

    They could use Azure Synapse Analytics.

2. How would Contoso schedule nightly data transfers from their OLTP database to their data warehouse?

    They would need to provision an instance of Azure Data Factory, and then utilize the Azure Data Factory Copy Wizard to setup a recurring copy from their SQL Database instance to existing tables in Azure Synapse Analytics. They could enable PolyBase in the Copy Wizard to speed up the copying process.

*Automated deployment*

1. How would you recommend Contoso implement their automated deployments?
   
   They could use GitHub Actions to deploy code into Azure. GitHub Actions can authenticate to Azure via a Service Principal established in Active Directory, or via a Publish Profile downloaded from the Azure portal; both of which are stored in repository secrets so they are not visible or checked into source control. Multiple GitHub Actions are available in the [GitHub Actions Marketplace](https://github.com/marketplace?query=Azure&type=actions) to aid in implementing automated releases. For Contoso, they are interested in releasing web application and Azure Function applications, both of which are available in the marketplace.

2. How would Contoso implement the trigger for the automated deployment?
   
   GitHub Actions are workflows defined using structured YML (pronounced YAML) files. In the workflow definition, Contoso can trigger their deployment workflow on **push** filtered by the **master** branch. Defined this way, the workflow will execute every time code is checked in to the master branch, including when a pull request is merged (the merge is considered a push of code).

## Checklist of preferred objection handling

1. It is not clear to us from the Azure Trust Center just how Azure helps our solution become PCI compliant.

    The Azure Trust Center helps you understand what Azure services have been certified for PCI compliance. For example, the services with which you could build a PCI compliant solution, but it does not describe how you build a PCI compliant solution on Azure. To fully accomplish a PCI compliant solution, you must address the requirements of PCI according to how you are handling cardholder data and the scope of your services. In many cases, Azure's PCI compliance attestations will be enough to satisfy aspects of PCI compliance for your solution, but there are at minimum some items which you must handle as a part of building your application, it is up to you to define and enforce secure password policies.

2. Can we provide a solution that scales to meet our public demand, but is also secure for use by our call center and warehouse?

    Yes. Azure can provide a solution that is both scalable and secure.

3. Our PCI compliance requires us to have a quarterly audit and to conduct occasional penetration tests. Is this supported by Azure?

    Although prior approval is not required, you may still formally document upcoming penetration testing engagements against Azure by filling out the Azure Service Penetration Testing Notification Form (<https://portal.msrc.microsoft.com/en-us/engage/pentest>).

    - Penetration testing must be conducted in accordance with our terms and conditions and comply with the Microsoft Cloud Unified Penetration Testing Rules of Engagement (<https://technet.microsoft.com/mt784683>).

    - Tests that would cause a Denial of Service (DoS) are prohibited.

4. Can we audit the Azure data center?

    No. Our independent audits and certifications are shared with customers in lieu of individual customer audits. These certifications and attestations accurately represent how we obtain and meet our security and compliance objectives, and serve as a practical mechanism to validate our promises for all customers. Allowing potentially thousands of customers to audit our services would not be a scalable practice and might compromise security and privacy. Our independent third-party validation program includes audits that are conducted on an annual basis to provide verification of Azure security controls.

5. In the past, we have relied on SOASTA CloudTest to design and execute our web load tests at scale. In moving to Azure, are we still able to capitalize on CloudTest?

    Yes. Azure is a supported cloud provider for CloudTest, and your applications hosted in Azure can have load and performance tests conducted against them from SOASTA's global network of cloud resources, while monitoring results in their big-data, real-time streaming analytics platform.

6. Our previous infrastructure did not have great performance monitoring of our websites. What options would you recommend we investigate that would work with our web apps in Azure?

    Web apps in Azure include first-class support for both Microsoft Application Insights and NewRelic Application Performance Monitoring, both of which enable you to collect performance telemetry from your web apps as they are running. You can view and analyze traces from both server-side and browser-side telemetry, diagnose errors, and set alerts from within the Azure Portal. Contoso can also capitalize on Log Analytics, a feature of Microsoft Operations Management Suite, by having the Application Insights logs or the Web App Diagnostic logs pushed to a Storage Account and then picked up and made searchable using the Custom Log. Alternately, they can also push their New Relic logs into Log Analytics, as well giving them a single pane of glass to do all their monitoring through Operations Management Suite.

7. We have heard that Azure's data warehouse can be paused. Does that mean we must store all our data in Azure Storage first before we can pause the instances and risk losing our data?

    Azure Synapse Analytics uses storage in two ways, and both enable the data to exist even while the SQL DW instance is paused. For data that is managed by Azure Synapse Analytics (e.g., it is inserted directly into relational or columnar tables), it is stored in Azure Premium Storage. For data supporting external tables in SQL DW, this data resides in Azure Standard Storage and is referenced via PolyBase, a component of Azure Synapse Analytics.

8. We know it's possible to use Azure SQL Database as our data warehouse. What should we consider when deciding between this and Azure Synapse Analytics?

    It is true that Azure SQL Database can be used as a data warehouse. This is considered an SMP-based warehouse, or symmetric multiprocessing. Azure Synapse Analytics is classified as an MPP-based warehouse, or massively parallel processing. As a rule, SMP-based warehouses are best suited for small to medium data sets (up to 4-100 TB), while MPP is often used for big data. The delineation between small/medium and big data is partly to do with your organization's definition and supporting infrastructure.

    Beyond data sizes, the type of workload pattern is likely to be a greater determining factor. For example, complex queries may be too slow for an SMP solution, and require an MPP solution instead. MPP-based systems are likely to impose a performance penalty with small data sizes, due to the way jobs are distributed and consolidated across nodes. If your data sizes already exceed 1 TB and are expected to continually grow, consider selecting an MPP solution. However, if your data sizes are less than this, but your workloads are exceeding the available resources of your SMP solution, then MPP may be your best option as well. Given this, consider Azure Synapse Analytics for small and medium datasets, where the workload is compute and memory intensive.

    Azure Synapse Analytics provides CSLA with a datastore that contains pre-aggregated data using column names that make sense to business users and analysts, a restructured schema to simplify data relationships, and consolidated tables. It also keeps historical data separate from the source transaction systems for performance reasons.

## Customer quote (to be read back to the attendees at the end)

"I can sleep better at night knowing that our e-commerce solution is scalable to handle our biggest days, doesn't sacrifice our required PCI compliance, and actually lowers our infrastructure burden."

Miles Strom, CEO of Contoso Sports League Association
